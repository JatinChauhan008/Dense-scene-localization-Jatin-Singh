{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Cell 1: Install Dependencies\n",
        "This cell installs all the necessary Python packages for the script to run"
      ],
      "metadata": {
        "id": "WK9h2izVnT8s"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "weVZ4mENnKDK"
      },
      "outputs": [],
      "source": [
        "\n",
        "print(\"[1/6] Installing required libraries...\")\n",
        "!pip install -q torch torchvision transformers Pillow gdown\n",
        "print(\" Libraries installed successfully.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Cell 2: User Configuration\n",
        "Please Change the image path and set the Query you want to prompt in this cell"
      ],
      "metadata": {
        "id": "oKOww0iEnX29"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "IMAGE_PATH = \"Update your Image Path here \"                                      #Please Change the path here for the image you want to test\n",
        "\n",
        "SAMPLE_QUERIES = [\n",
        "    \"Enter your Query here \"                                                     #Please Enter your Query here\n",
        "]\n",
        "\n",
        "GDRIVE_DINO_ZIP_ID = \"1GiwAIi0g--4fkXP-kP7h6umnfpvy5YHZ\"\n",
        "GDRIVE_CLIP_ZIP_ID = \"1obrnuPoL3IkXD9tkjW6mDBwYWZTsrjnl\""
      ],
      "metadata": {
        "id": "S2r914fenaHN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Cell 3: Download and Extract Custom Models\n",
        "This cell downloads the .zip files from the Google Drive links provided in Cell 2. It then extracts them into the Colab environment so they can be used by the script."
      ],
      "metadata": {
        "id": "cXEv30Alnb5j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "print(\"\\\\n [2/6] Downloading and extracting custom models from Google Drive...\")\n",
        "import os\n",
        "import gdown\n",
        "import zipfile\n",
        "import sys\n",
        "\n",
        "try:\n",
        "    dino_zip_path = \"grounding-dino-base.zip\"\n",
        "    clip_zip_path = \"clip-vit-base-patch32.zip\"\n",
        "\n",
        "    print(\"   - Attempting to download Grounding DINO folder...\")\n",
        "    gdown.download(f\"https://drive.google.com/uc?id={GDRIVE_DINO_ZIP_ID}\", dino_zip_path, quiet=False)\n",
        "\n",
        "    print(\"   - Attempting to download CLIP folder...\")\n",
        "    gdown.download(f\"https://drive.google.com/uc?id={GDRIVE_CLIP_ZIP_ID}\", clip_zip_path, quiet=False)\n",
        "\n",
        "    if not os.path.exists(dino_zip_path) or not os.path.exists(clip_zip_path):\n",
        "        raise FileNotFoundError(\"A required model zip file failed to download.\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"   -  An error occurred during download: {e}\")\n",
        "    print(\"   - Please check your File IDs and sharing permissions in Cell 2.\")\n",
        "    sys.exit()\n",
        "\n",
        "\n",
        "try:\n",
        "    print(f\"\\\\n   - Unzipping {dino_zip_path}...\")\n",
        "    with zipfile.ZipFile(dino_zip_path, 'r') as zip_ref:\n",
        "        zip_ref.extractall(\"./\")\n",
        "    print(\"   -  Grounding DINO extracted successfully.\")\n",
        "\n",
        "    print(f\"   - Unzipping {clip_zip_path}...\")\n",
        "    with zipfile.ZipFile(clip_zip_path, 'r') as zip_ref:\n",
        "        zip_ref.extractall(\"./\")\n",
        "    print(\"   - CLIP extracted successfully.\")\n",
        "except Exception as e:\n",
        "    print(f\"   -  An error occurred during extraction: {e}\")\n",
        "    sys.exit()\n",
        "\n",
        "print(\"\\\\n Custom models are ready.\")"
      ],
      "metadata": {
        "id": "hQwFudMQneIJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Cell 4: Imports and Environment Setup\n",
        "This cell imports the required libraries, suppresses unnecessary warnings, sets the computation device (GPU if available), and creates the output directory."
      ],
      "metadata": {
        "id": "batffT1-nflO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "print(\"\\\\n [3/6] Importing libraries and setting up the environment...\")\n",
        "import torch\n",
        "import os\n",
        "from PIL import Image, ImageDraw, ImageFont\n",
        "from torchvision.ops import nms\n",
        "import warnings\n",
        "from transformers import AutoProcessor, AutoModelForZeroShotObjectDetection, CLIPProcessor, CLIPModel\n",
        "\n",
        "\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "\n",
        "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"   - Using device: {DEVICE}\")\n",
        "\n",
        "os.makedirs(\"final_output\", exist_ok=True)\n",
        "print(\"   - Created output directory: 'final_output/'\")\n",
        "print(\" Setup complete.\")"
      ],
      "metadata": {
        "id": "WA9LPTG1njiI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Cell 5: Core Processing Functions\n",
        "This cell defines all the core logic: loading the models from the extracted folders, getting candidate boxes with Grounding DINO, refining them with CLIP, and drawing the final output."
      ],
      "metadata": {
        "id": "CtAemYfSnlM6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "print(\"\\\\n [4/6] Defining processing functions...\")\n",
        "\n",
        "def load_models():\n",
        "    print(\"\\\\n   - Loading all required models from local folders...\")\n",
        "\n",
        "\n",
        "    local_dino_path = \"./grounding-dino-base\"\n",
        "    local_clip_path = \"./clip-vit-base-patch32\"\n",
        "\n",
        "\n",
        "    try:\n",
        "        print(f\"   - Loading Grounding DINO model from: {local_dino_path}\")\n",
        "        g_dino_processor = AutoProcessor.from_pretrained(local_dino_path)\n",
        "        g_dino_model = AutoModelForZeroShotObjectDetection.from_pretrained(local_dino_path)\n",
        "        g_dino_model = g_dino_model.to(DEVICE).eval()\n",
        "        print(\"   -  Custom Grounding DINO model loaded successfully.\")\n",
        "    except Exception as e:\n",
        "        print(f\"   - Error loading custom Grounding DINO model: {e}\")\n",
        "        print(\"   - Please ensure the zip file contained the correct model folder.\")\n",
        "        return None\n",
        "\n",
        "    try:\n",
        "        print(f\"   - Loading CLIP model from: {local_clip_path}\")\n",
        "        clip_processor = CLIPProcessor.from_pretrained(local_clip_path)\n",
        "        clip_model = CLIPModel.from_pretrained(local_clip_path)\n",
        "        clip_model = clip_model.to(DEVICE).eval()\n",
        "        print(\"   - Custom CLIP model loaded successfully.\")\n",
        "    except Exception as e:\n",
        "        print(f\"   -  Error loading custom CLIP model: {e}\")\n",
        "        print(\"   - Please ensure the zip file contained the correct model folder.\")\n",
        "        return None\n",
        "\n",
        "    return {\n",
        "        \"g_dino\": (g_dino_model, g_dino_processor),\n",
        "        \"clip\": (clip_model, clip_processor)\n",
        "    }\n",
        "\n",
        "def get_candidate_boxes(g_dino_model, g_dino_processor, image, text_prompt, box_threshold=0.25):\n",
        "\n",
        "    inputs = g_dino_processor(images=image, text=text_prompt, return_tensors=\"pt\").to(DEVICE)\n",
        "    with torch.no_grad():\n",
        "        outputs = g_dino_model(**inputs)\n",
        "\n",
        "    target_sizes = torch.tensor([image.size[::-1]]).to(DEVICE)\n",
        "    results = g_dino_processor.post_process_grounded_object_detection(\n",
        "        outputs,\n",
        "        target_sizes=target_sizes,\n",
        "        threshold=box_threshold\n",
        "    )[0]\n",
        "    return results[\"boxes\"], results[\"scores\"]\n",
        "\n",
        "def apply_nms(all_boxes, all_scores, iou_threshold=0.5):\n",
        "\n",
        "    if all_boxes.numel() == 0:\n",
        "        return torch.empty((0, 4), device=DEVICE), torch.empty((0,), device=DEVICE)\n",
        "\n",
        "    indices = nms(all_boxes.to(DEVICE), all_scores.to(DEVICE), iou_threshold)\n",
        "    print(f\"   - NMS: Reduced {len(all_boxes)} boxes to {len(indices)}.\")\n",
        "    return all_boxes[indices], all_scores[indices]\n",
        "\n",
        "def rerank_with_clip(clip_model, clip_processor, image, boxes, dino_scores, text_prompt, clip_threshold=0.20):\n",
        "\n",
        "    if boxes.numel() == 0:\n",
        "        print(\"   - No candidate boxes to re-rank.\")\n",
        "        return None, None\n",
        "\n",
        "    crops = [image.crop(box.tolist()) for box in boxes]\n",
        "    text_inputs = clip_processor(text=[text_prompt], return_tensors=\"pt\", padding=True).to(DEVICE)\n",
        "    image_inputs = clip_processor(images=crops, return_tensors=\"pt\", padding=True).to(DEVICE)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        text_features = clip_model.get_text_features(**text_inputs).float()\n",
        "        image_features = clip_model.get_image_features(**image_inputs).float()\n",
        "        text_features /= text_features.norm(dim=-1, keepdim=True)\n",
        "        image_features /= image_features.norm(dim=-1, keepdim=True)\n",
        "        clip_scores = (text_features @ image_features.T).squeeze(0)\n",
        "\n",
        "    combined_scores = (0.5 * dino_scores.to(DEVICE)) + (0.5 * clip_scores)\n",
        "    best_idx = combined_scores.argmax().item()\n",
        "    best_clip_score = clip_scores[best_idx].item()\n",
        "\n",
        "    if best_clip_score < clip_threshold:\n",
        "        print(f\"   - No crop met the CLIP similarity threshold of {clip_threshold}.\")\n",
        "        return None\n",
        "\n",
        "    print(f\"   - Selected best crop with a combined score of: {combined_scores[best_idx].item():.4f}\")\n",
        "    return boxes[best_idx]\n",
        "\n",
        "def draw_final_box(image, box, text):\n",
        "\n",
        "    img_draw = image.copy()\n",
        "    draw = ImageDraw.Draw(img_draw)\n",
        "    draw.rectangle(box.tolist(), outline=\"lime\", width=5)\n",
        "\n",
        "    try:\n",
        "        font = ImageFont.truetype(\"arial.ttf\", 20)\n",
        "    except IOError:\n",
        "        font = ImageFont.load_default()\n",
        "    draw.text((box[0] + 5, box[1] + 5), text, fill=\"lime\", font=font)\n",
        "    return img_draw\n",
        "\n",
        "print(\" Core functions defined.\")"
      ],
      "metadata": {
        "id": "kgc8JbnBnog0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Cell 6: Main Execution Pipeline\n",
        "This is the final cell that runs the entire process. It loads the models and then iterates through each of your queries from Cell 2, saving a resulting image for each successful detection."
      ],
      "metadata": {
        "id": "fAPxRT2cnp08"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def run_pipeline():\n",
        "\n",
        "    try:\n",
        "        print(f\"\\\\n [5/6] Loading models into memory...\")\n",
        "        models = load_models()\n",
        "        if models is None:\n",
        "            return\n",
        "\n",
        "        print(f\"\\\\n [6/6] Processing image: '{IMAGE_PATH}'...\")\n",
        "        input_image = Image.open(IMAGE_PATH).convert(\"RGB\")\n",
        "\n",
        "\n",
        "        for query in SAMPLE_QUERIES:\n",
        "            print(f\"\\\\n{'='*20} PROCESSING QUERY: '{query}' {'='*20}\")\n",
        "\n",
        "\n",
        "            all_boxes, all_scores = get_candidate_boxes(\n",
        "                models[\"g_dino\"][0], models[\"g_dino\"][1], input_image, query\n",
        "            )\n",
        "\n",
        "            if all_boxes.nelement() == 0:\n",
        "                print(\"❌ No initial candidate boxes found by Grounding DINO for this query.\")\n",
        "                continue\n",
        "\n",
        "\n",
        "            merged_boxes, merged_scores = apply_nms(all_boxes, all_scores)\n",
        "\n",
        "            final_box = rerank_with_clip(\n",
        "                models[\"clip\"][0], models[\"clip\"][1], input_image, merged_boxes, merged_scores, query\n",
        "            )\n",
        "\n",
        "            if final_box is not None:\n",
        "                query_slug = query.replace(\" \", \"_\").replace(\"'\", \"\")\n",
        "                final_image_with_box = draw_final_box(input_image, final_box, query)\n",
        "                output_path = f\"final_output/{query_slug}_result.jpg\"\n",
        "                final_image_with_box.save(output_path)\n",
        "                print(f\"✅ Success! Saved result to '{output_path}'\")\n",
        "            else:\n",
        "                print(f\"❌ Could not determine a final crop for the query: '{query}'\")\n",
        "\n",
        "        print(f\"\\\\n{'='*20} PIPELINE FINISHED {'='*20}\")\n",
        "\n",
        "    except FileNotFoundError:\n",
        "        print(f\"\\\\n\\\\n❌ ERROR: Cannot find the image at '{IMAGE_PATH}'.\")\n",
        "        print(\"   - Please check the file name in 'CELL 2: User Configuration'.\")\n",
        "        print(\"   - Make sure you have uploaded the image to your Colab session.\")\n",
        "    except Exception as e:\n",
        "        print(f\"\\\\n\\\\n❌ An unexpected error occurred: {e}\")\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    run_pipeline()"
      ],
      "metadata": {
        "id": "C2L8ADo4ntoa"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}